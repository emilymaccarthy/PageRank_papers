{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "from matricesRalas import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PRINT = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W, D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generar las matrices $\\mathbf{W}$ y $\\mathbf{D}$ a partir de la tabla citas.csv. Utilizar matrices ralas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: = 629814\n"
     ]
    }
   ],
   "source": [
    "papers = 'papers/papers.csv'\n",
    "citas = 'papers/citas.csv'\n",
    "\n",
    "\n",
    "W = MatrizRala.getW(papers,citas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "D:MatrizRala = W.getD()\n",
    "\n",
    "\n",
    "if(PRINT):\n",
    "    print(W,D)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido al tamaño del conjunto de datos, no podemos resolver explıcitamente usando Gauss-Jordan el sistema. Utilizando d = 0,85 y asumiendo una distribucion equiprobable para el tiempo 1, computar pt hasta que la serie converja. Es decir, que la diferencia $∥p_{t+1} − p_{t}∥$ sea menor a cierto $ϵ > 0$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardamos W y D de forma que no sea necesario correr el codigo nuevamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "GUARDAR = False\n",
    "\n",
    "if(GUARDAR):\n",
    "    # Serializar el objeto\n",
    "    with open('mat_W.pkl', 'wb') as archivo:\n",
    "        pickle.dump(W, archivo)\n",
    "        archivo.close()\n",
    "\n",
    "    # Serializar el objeto\n",
    "    with open('mat_D.pkl', 'wb') as archivo:\n",
    "        pickle.dump(D, archivo)\n",
    "        archivo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "RECUPERAR = False\n",
    "\n",
    "if RECUPERAR:\n",
    "\n",
    "    # Deserializar el objeto\n",
    "    W: MatrizRala = None\n",
    "    D: MatrizRala = None\n",
    "    with open('mat_W.pkl', 'rb') as archivo:\n",
    "        W = pickle.load(archivo)\n",
    "        archivo.close()\n",
    "\n",
    "    with open('mat_D.pkl', 'rb') as archivo:\n",
    "        D = pickle.load(archivo)\n",
    "        archivo.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metodo Iterativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "d = 0.85\n",
    "\n",
    "epsilon = 0.0001\n",
    "    \n",
    "N = W.shape[0]\n",
    "    \n",
    "#distribucion equiprobable \n",
    "p_t = MatrizRala.getVectorOne(N) * (1/ N)\n",
    "        \n",
    "#matriz de unos\n",
    "unos = MatrizRala.getVectorOne(N)\n",
    "    \n",
    "diff_abs = []\n",
    "contador = 0    \n",
    "diff = 1\n",
    "parte_div = (1 - d) / N\n",
    "WD = W.mul_daig(D)\n",
    "\n",
    "dWD = d * WD\n",
    "\n",
    "while diff > epsilon:\n",
    "        \n",
    "    #caculos intermedios\n",
    "    dWDP_t = dWD.mul_con_vec_col(p_t)\n",
    "    p_t_mas1 = parte_div * unos + dWDP_t\n",
    "    p_t = p_t_mas1\n",
    "        \n",
    "    #calcular la diferencia con p* osea seria entre p* o p_t\n",
    "    diff = MatrizRala.diffVectors(p_t_mas1,p_t) \n",
    "    diff_abs.append(diff)\n",
    "    contador +=1 \n",
    "    print(diff)\n",
    "\n",
    "t = contador\n",
    "diffs = diff_abs \n",
    "p_sol = p_t_mas1\n",
    "\n",
    "if(PRINT):\n",
    "    print(f\"Convergencia alcanzada en la iteración {t + 1}.\")\n",
    "    print(\"Resultado\")\n",
    "    print(p_sol)\n",
    "    build_graph(t,diffs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sacamos los 10 con mayor impacto "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Armar la lista de los 10 papers con mayor impacto. Comparar los resultados con aquellos obtenidos\n",
    "utilizando unicamente la cantidad de citas. ¿Que conclusiones se pueden sacar?, ¿Que algoritmo parece\n",
    "dar resultados mas satisfactorios?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00022817]\n",
      " [0.00021887]\n",
      " [0.00021237]\n",
      " [0.00020855]\n",
      " [0.0002063 ]\n",
      " [0.00018426]\n",
      " [0.00018144]\n",
      " [0.00017266]\n",
      " [0.0001707 ]\n",
      " [0.00016586]]\n",
      "[[2.28174822e-04 6.29813000e+05]\n",
      " [2.18867513e-04 6.29812000e+05]\n",
      " [2.12374980e-04 6.29811000e+05]\n",
      " [2.08554017e-04 6.29810000e+05]\n",
      " [2.06302999e-04 6.29809000e+05]\n",
      " [1.84261090e-04 6.29808000e+05]\n",
      " [1.81436434e-04 6.29807000e+05]\n",
      " [1.72664939e-04 6.29806000e+05]\n",
      " [1.70699835e-04 6.29805000e+05]\n",
      " [1.65856526e-04 6.29804000e+05]]\n"
     ]
    }
   ],
   "source": [
    "# los 10 papers con mas influencia seria los que en el vecto r de probabilidades tienen la probabilidad mas alta ?\n",
    "# sacar la posicion del vector de probabilidades \n",
    "# ir a la listaa de id con la posicion sacar el id y encontrarlo en el csv \n",
    "# sino directmaente ir al csv y buscar la posicion esa y sacar el nombre o la fila completa y guardar eso tipo saber cual es el numero 1 2 3 4 ... 10\n",
    "# recorrer W y fijarte cual es la que tiene mas cantidad de citas , sacar la posicion de esas (modificar la funcion que crea D)\n",
    "# papers = 'papers/papers.csv'\n",
    "# TOP_PAPAERS = 10\n",
    "# IDS,nombres = generarIDs(papers)\n",
    "# print(nombres[:TOP_PAPAERS+1])\n",
    "\n",
    "####\n",
    "    \n",
    "p_solNumpy = p_sol.toNumpy()\n",
    "\n",
    "orden_desc = np.argsort(p_solNumpy, axis=0)[::-1]\n",
    "p_solNumpy_sin_indices = np.sort(p_solNumpy, axis=0)[::-1]\n",
    "print(p_solNumpy_sin_indices[:10])\n",
    "\n",
    "indices_filas = np.arange(p_solNumpy.shape[0]).reshape((-1, 1))\n",
    "p_solNumpy_con_indices = np.hstack((p_solNumpy, indices_filas))\n",
    "#\n",
    "# ordenar de mayor a menor\n",
    "argSort = np.argsort(p_solNumpy_con_indices, axis=0)[::-1]# ordena de mayor a menor\n",
    "p_solNumpy_arreglado = np.sort(p_solNumpy_con_indices, axis=0)[::-1]\n",
    "\n",
    "\n",
    "print(p_solNumpy_arreglado[:10])\n",
    "# print(type(p_solNumpy))\n",
    "\n",
    "# print(np.sum(p_solNumpy))\n",
    "\n",
    "#print(argSort)\n",
    "top10 = p_solNumpy_arreglado[:10]\n",
    "\n",
    "# vectorRala = MatrizRala.fromNumpy(vectorNumpy)\n",
    "# print(vectorRala)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ids de papers \n",
    "def generarIDs(paper):\n",
    "    ids = []\n",
    "    nombres = []\n",
    "    \n",
    "    with open(paper, newline='',encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            # ids.append(row[0])\n",
    "            nombres.append(row[1])\n",
    "            # cada posicion de ids nos dice la citacion que vamos a hacer en W\n",
    "    \n",
    "    return nombres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "629813\n",
      "629812\n",
      "629811\n",
      "629810\n",
      "629809\n",
      "629808\n",
      "629807\n",
      "629806\n",
      "629805\n",
      "629804\n",
      "['Oppositional target domain estimation using grid-based simulation', 'Computer System Architecture', 'Multimodal system evaluation using modality efficiency and synergy metrics', 'Review article', 'Mining A', 'The Grid as a Single Entity: Towards a Behavior Model of the Whole Grid', 'Busy period analysis of finite QBD processes', 'Effectiveness and usability of an online help agent embodied as a talking head', 'Editorial: color in image and video processing', 'SENTINEL: a semantic business process monitoring tool']\n"
     ]
    }
   ],
   "source": [
    "list10 = []\n",
    "nombres = generarIDs(papers)\n",
    "for i in range(len(top10)):\n",
    "    id = int(top10[i][1])\n",
    "    print(id)\n",
    "    list10.append(nombres[id])\n",
    "\n",
    "print(list10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open(papers,newline='',encoding='utf-8') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader)\n",
    "    \n",
    "    for row in reader:\n",
    "        for i in range(len(top10)):\n",
    "          \n",
    "            if top10[i][1] == row[0]:\n",
    "                list10.append(row[1])\n",
    "                break  \n",
    "        \n",
    "    csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Oppositional target domain estimation using grid-based simulation', 'Computer System Architecture', 'Multimodal system evaluation using modality efficiency and synergy metrics', 'Review article', 'Mining A', 'The Grid as a Single Entity: Towards a Behavior Model of the Whole Grid', 'Busy period analysis of finite QBD processes', 'Effectiveness and usability of an online help agent embodied as a talking head', 'Editorial: color in image and video processing', 'SENTINEL: a semantic business process monitoring tool']\n"
     ]
    }
   ],
   "source": [
    "print(list10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "588a077454552c0b608c7a75f739e0012bc0a6317cbb2228f1831255df17ce82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
